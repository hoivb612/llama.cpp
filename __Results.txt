Unless otherwise noted, the data comes from b612_llama_dc branch

pp is much faster in b612_llama_dc (180+ tps)!!!!
tg is much faster in b612_dc_080625 (60+ tps)!!!!


					b612					b612_dc					b612.llama_dc
			=================================================================================================================================

Phi-3-Q4_K_M-MS		pp128		- full-time repacking -			 37.38 + t2 + paffin			 38.25 + t2 + paffin
			 tg64							 19.29					 25.82
										 22.45 + t2*+ paffin			 38.75 + t2*+ paffin
										 16.63	(12.22)				 24.49

			pp128		 65.58 + t2 + 00011000 + Q4_K_8x8	 73.71 + t2 + paffin + Q4_K_8x8		 76.38 + t2 + paffin + Q4_K_8x8
			 tg64		 20.69					 22.05					 13.37
					 66.32 + t2*+ 00011000 + Q4_K_8x8	 62.77 + t2*+ paffin + Q4_K_8x8		 74.31 + t2*+ paffin + Q4_K_8x8
					 19.66					 22.39					 23.24

			pp128		 68.49 + t2 + 00001100 + Q4_K_8x8	- no Xbox repacking -			 47.57 + t2 + paffin + Q4_K_x8
			 tg64		 20.37										 26.36
					 70.40 + t2*+ 00001100 + Q4_K_8x8						 47.95 + t2*+ paffin + Q4_K_x8
					 20.08										 25.09
			-----

			pp128		- full-time repacking -			 70.12 + t4 + paffin			 72.94 + t4 + paffin
			 tg64							 30.02					 35.23
										 50.42 + t4*+ paffin			 75.70 + t4*+ paffin
										 26.91					 40.11

			pp128		126.85 + t4 + 000aa000 + Q4_K_8x8	141.86 + t4 + paffin + Q4_K_8x8		146.69 + t4 + paffin + Q4_K_8x8
			 tg64		 30.31					 31.74					 23.73
					124.25 + t4*+ 000aa000 + Q4_K_8x8	123.51 + t4*+ paffin + Q4_K_8x8		148.56 + t4*+ paffin + Q4_K_8x8
					 32.91					 36.92					 38.53

			pp128		101.64 + t4 + 0000aa00 + Q4_K_8x8	- no Xbox repacking -			 88.81 + t4 + paffin + Q4_K_x8
			 tg64		 21.53 										 38.87
					127.44 + t4*+ 0000aa00 + Q4_K_8x8						 92.99 + t4*+ paffin + Q4_K_x8
					 22.43										 40.98
			-----

			pp128		- full-time repacking -			100.94 + t8 + paffin 			125.39 + t8 + paffin 
			 tg64							 38.12					 36.31
										 82.72 + t8*+ paffin			134.58 + t8*+ paffin
										 36.85					 41.06

			pp128		163.80 + t8 + 00aaaa00 + Q4_K_8x8	204.22 + t8 + paffin + Q4_K_8x8		244.66 + t8 + paffin + Q4_K_8x8
			 tg64		 37.02					 39.08					 38.49
					201.18 + t8*+ 00aaaa00 + Q4_K_8x8	213.22 + t8*+ paffin + Q4_K_8x8		259.00 + t8*+ paffin + Q4_K_8x8
					 37.35					 39.26					 41.05

			pp128		- no Xbox repacking -			- no Xbox repacking -			150.06 + t8 + paffin + Q4_K_x8
			 tg64												 41.90 (36.25)
															159.77 + t8*+ paffin + Q4_K_x8
															 41.77
			-----


Phi-3-Q2_K-MS		pp128		- full-time repacking -			 38.46 + t2 + paffin			 40.57 + t2 + paffin
			 tg64							 22.57					 32.02
										 25.88 + t2*+ paffin			 40.55 + t2*+ paffin
										 16.09					 30.78

			pp128		 38.54 + t2 + 00011000 + Q2_K_8x8	 38.59 + t2 + paffin + Q2_K_8x8		 46.71 + t2 + paffin + Q2_K_8x8
			 tg64		 20.43					 22.53					 27.00
					 39.05 + t2*+ 00011000 + Q2_K_8x8	 18.04 + t2*+ paffin + Q2_K_8x8		 46.90 + t2*+ paffin + Q2_K_8x8
					 20.54					 16.20					 26.36

			pp128		 39.90 + t2 + 00001100 + Q2_K_8x8	- no Xbox repacking -			 58.10 + t2 + paffin + Q2_K_x8
			 tg64		 21.25										 37.68
					 40.63 + t2*+ 00001100 + Q2_K_8x8						 59.08 + t2*+ paffin + Q2_K_x8
					 21.71										 36.56
			-----

			pp128		- full-time repacking -			 51.59 + t4 + paffin			 77.34 + t4 + paffin
			 tg64		 					 31.15					 49.68
			pp128		- full-time repacking -			 53.63 + t4*+ paffin			 79.02 + t4*+ paffin
			 tg64							 31.39					 53.70

			pp128		 74.31 + t4 + 000aa000 + Q2_K_8x8	- no Q2_K repack -			 91.22 + t4 + paffin + Q2_K_8x8
			 tg64		 35.16					 					 44.78
					 73.75 + t4*+ 000aa000 + Q2_K_8x8						 90.18 + t4*+ paffin + Q2_K_8x8
					 36.96										 47.49

			pp128		- no Xbox repacking -			- no Q2_K repack -			112.08 + t4 + paffin + Q2_K_x8
			 tg64												 53.98
															110.43 + t4*+ paffin + Q2_K_x8
															 58.16
			-----

			pp128		- full-time repacking -			119.59 + t8 + paffin			131.53 + t8 + paffin
			 tg64		 					 46.33					 53.16
			pp128		- full-time repacking -			 92.51 + t8*+ paffin			135.42 + t8*+ paffin
			 tg64							 47.70					 59.94

			pp128		100.95 + t8 + 00aaaa00 + Q2_K_8x8	- no Q2_K repack -			157.88 + t8 + paffin + Q2_K_8x8
			 tg64		 45.20					 					 57.85
					129.53 + t8*+ 00aaaa00 + Q2_K_8x8						161.67 + t8*+ paffin + Q2_K_8x8
					 53.10										 59.69

			pp128		- no Xbox repacking -			- no Q2_K repack -			187.00 + t8 + paffin + Q2_K_x8
			 tg64												 55.59
															198.13 + t8*+ paffin + Q2_K_x8
															 62.37
															123.87 + t8 + paffin + Q2_K_x8 + b612_dc_080625
															 62.97



=========================================================================================================================================================================

From 395LT:

C:\llama.cpp\b612.dc_080625\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 2
ggml_cpu_init: from ggml-cpu-b612.c - calling ggml!ggml_init() to initialize fp16 tables
ggml_cpu_init: from ggml-cpu-b612.c - initializing GELU, SILU and EXP fp32 tables
ggml_cpu_set_tensor_repack_mode: set tensor repacking to 2



system_info: CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | OPENMP = 1 | REPACK = 1 |

| model                          |       size |     params | backend    | threads |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |           pp128 |        113.49 ± 0.32 |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |            tg64 |         61.81 ± 0.16 |


=== Elapsed time:    13.43s


          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20928     0.04   0.33       1.74 GGML_OP_ADD
   21255     0.03   0.25       1.30 GGML_OP_MUL
   21255     0.02   0.18       0.91 GGML_OP_RMS_NORM
   94503    10.52  95.73     111.28 GGML_OP_MUL_MAT
   10464     0.02   0.14       1.45 GGML_OP_CONT
     981     0.00   0.05       5.05 GGML_OP_GET_ROWS
   20928     0.19   1.71       8.99 GGML_OP_SET_ROWS
   10464     0.06   0.56       5.90 GGML_OP_SOFT_MAX
   20928     0.07   0.66       3.48 GGML_OP_ROPE
   10464     0.04   0.39       4.11 GGML_OP_GLU

  232170    10.99 100.00

Graph Size  #_Nodes  #_Tensors
 1126         327      368202

Total         327      368202
Total OPs Tensors      232170
Total NOP Tensors      136032 (skipped)

vector dot matrix multiply type frequency
   Count     %    Time(ms)       %   init_mat(ms) vec_dot_type
   20928   22.15     336.83     3.20     42.20    GGML_TYPE_f16
     327    0.35     246.47     2.34      0.39    GGML_TYPE_q8_K
   41856   44.29    5604.26    53.29     90.03    GGML_TYPE_q2_K_q8_K_x8
   31392   33.22    4328.94    41.16     95.24    GGML_TYPE_q3_K_q8_K_x8

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(ms) Src0 Type

   20928     0.33   3.16     0.02 ggml_type_f16
     327     0.25   2.35     0.75 ggml_type_q6_K
   41856     5.60  53.32     0.13 ggml_type_q2_K_x8
   31392     4.32  41.18     0.14 ggml_type_q3_K_x8

   94503    10.50 100.00

total number of mul_mat init conversions 94503
total elapsed init conversion time  0.23sec
average init conversion time  2.41us

total number of mul_mat repack conversions 224
total number of FAILED mul_mat repack conversions 0
total elapsed repack conversion time  1.24sec
average repack conversion time 5546.37us

vector row size count histogram for quant type: f16

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
    64    5152  24.62      40.86      0.09      4.29
   128    5120  24.46      35.47      0.09      5.14
   192   10464  50.00     167.44      0.54     24.48
   256     192   0.92      93.06      0.53      8.29

         20928 100.00     336.83 (avg row size 145)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
               96  128   96  128      0.54

vector row size count histogram for quant type: q6_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  2520     327  100.00     246.47      9.47      0.39

           327 100.00     246.47 (avg row size 2520)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 32064 3072 32064      9.47

vector row size count histogram for quant type: q2_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1008   41856  100.00    5604.26      7.45     90.03

         41856 100.00    5604.26 (avg row size 1008)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 8192 3072 8192      7.45

vector row size count histogram for quant type: q3_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1320   20928  66.67    1914.59      3.61     49.93
  3520   10464  33.33    2414.35      8.01     45.31

         31392 100.00    4328.94 (avg row size 2053)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             8192 3072 8192 3072      8.01


build: 9f51f2a1 (6209)

C:\llama.cpp\b612.dc_080625\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 4
ggml_cpu_init: from ggml-cpu-b612.c - calling ggml!ggml_init() to initialize fp16 tables
ggml_cpu_init: from ggml-cpu-b612.c - initializing GELU, SILU and EXP fp32 tables
ggml_cpu_set_tensor_repack_mode: set tensor repacking to 4



system_info: CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | OPENMP = 1 | REPACK = 1 |

| model                          |       size |     params | backend    | threads |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |           pp128 |        94.27 ± 11.75 |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |            tg64 |         62.12 ± 0.12 |


=== Elapsed time:    13.53s


          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20928     0.02   0.20       1.19 GGML_OP_ADD
   21255     0.03   0.22       1.29 GGML_OP_MUL
   21255     0.02   0.15       0.89 GGML_OP_RMS_NORM
   94503    12.02  96.05     127.18 GGML_OP_MUL_MAT
   10464     0.02   0.14       1.69 GGML_OP_CONT
     981     0.01   0.04       5.33 GGML_OP_GET_ROWS
   20928     0.24   1.95      11.66 GGML_OP_SET_ROWS
   10464     0.05   0.43       5.19 GGML_OP_SOFT_MAX
   20928     0.07   0.54       3.25 GGML_OP_ROPE
   10464     0.03   0.27       3.18 GGML_OP_GLU

  232170    12.51 100.00

Graph Size  #_Nodes  #_Tensors
 1126         327      368202

Total         327      368202
Total OPs Tensors      232170
Total NOP Tensors      136032 (skipped)

vector dot matrix multiply type frequency
   Count     %    Time(ms)       %   init_mat(ms) vec_dot_type
   20928   22.15     342.52     2.85     39.07    GGML_TYPE_f16
   73575   77.85   11676.57    97.15    143.45    GGML_TYPE_q8_K

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(ms) Src0 Type

   20928     0.34   2.81     0.02 ggml_type_f16
   41856     6.00  50.04     0.14 ggml_type_q2_K
   31392     5.41  45.09     0.17 ggml_type_q3_K
     327     0.25   2.05     0.75 ggml_type_q6_K

   94503    12.00 100.00

total number of mul_mat init conversions 94503
total elapsed init conversion time  0.18sec
average init conversion time  1.93us

total number of mul_mat repack conversions 0
total number of FAILED mul_mat repack conversions 0

vector row size count histogram for quant type: f16

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
    64    5152  24.62      39.52      0.09      4.14
   128    5120  24.46      38.60      0.09      4.68
   192   10464  50.00     167.65      0.82     21.87
   256     192   0.92      96.76      0.59      8.38

         20928 100.00     342.52 (avg row size 145)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
               96  128   96  128      0.82

vector row size count histogram for quant type: q2_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1008   41856  100.00    6013.25      8.60     69.38

         41856 100.00    6013.25 (avg row size 1008)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 8192 3072 8192      8.60

vector row size count histogram for quant type: q3_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1320   20928  66.67    2409.71      4.86     40.32
  3520   10464  33.33    3007.63     14.70     33.41

         31392 100.00    5417.34 (avg row size 2053)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             8192 3072 8192 3072     14.70

vector row size count histogram for quant type: q6_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  2520     327  100.00     245.98      7.53      0.34

           327 100.00     245.98 (avg row size 2520)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 32064 3072 32064      7.53


build: 9f51f2a1 (6209)

C:\llama.cpp\b612.dc_080625\build>
C:\llama.cpp\b612.dc_080625\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 3
ggml_cpu_init: from ggml-cpu-b612.c - calling ggml!ggml_init() to initialize fp16 tables
ggml_cpu_init: from ggml-cpu-b612.c - initializing GELU, SILU and EXP fp32 tables
ggml_cpu_set_tensor_repack_mode: set tensor repacking to 3



system_info: CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | OPENMP = 1 | REPACK = 1 |

| model                          |       size |     params | backend    | threads |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |           pp128 |        113.68 ± 0.40 |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |            tg64 |         62.38 ± 0.13 |


=== Elapsed time:    14.09s


          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20928     0.03   0.24       1.23 GGML_OP_ADD
   21255     0.03   0.28       1.38 GGML_OP_MUL
   21255     0.02   0.18       0.90 GGML_OP_RMS_NORM
   94503    10.13  94.99     107.17 GGML_OP_MUL_MAT
   10464     0.02   0.15       1.55 GGML_OP_CONT
     981     0.00   0.04       4.54 GGML_OP_GET_ROWS
   20928     0.29   2.71      13.79 GGML_OP_SET_ROWS
   10464     0.05   0.45       4.55 GGML_OP_SOFT_MAX
   20928     0.07   0.66       3.35 GGML_OP_ROPE
   10464     0.03   0.31       3.14 GGML_OP_GLU

  232170    10.66 100.00

Graph Size  #_Nodes  #_Tensors
 1126         327      368202

Total         327      368202
Total OPs Tensors      232170
Total NOP Tensors      136032 (skipped)

vector dot matrix multiply type frequency
   Count     %    Time(ms)       %   init_mat(ms) vec_dot_type
   20928   22.15     344.03     3.40     40.22    GGML_TYPE_f16
     327    0.35     243.38     2.40      0.31    GGML_TYPE_q8_K
   41856   44.29    5373.58    53.06     77.61    GGML_TYPE_q2_K_q8_K_x8
   31392   33.22    4166.81    41.14     82.21    GGML_TYPE_q3_K_q8_K_x8

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(ms) Src0 Type

   20928     0.34   3.36     0.02 ggml_type_f16
     327     0.24   2.41     0.74 ggml_type_q6_K
   41856     5.36  53.08     0.13 ggml_type_q2_K_x8
   31392     4.16  41.16     0.13 ggml_type_q3_K_x8

   94503    10.11 100.00

total number of mul_mat init conversions 94503
total elapsed init conversion time  0.20sec
average init conversion time  2.12us

total number of mul_mat repack conversions 224
total number of FAILED mul_mat repack conversions 0
total elapsed repack conversion time  2.31sec
average repack conversion time 10304.74us

vector row size count histogram for quant type: f16

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
    64    5152  24.62      38.00      0.17      4.18
   128    5120  24.46      36.38      0.10      4.99
   192   10464  50.00     171.58      0.67     22.75
   256     192   0.92      98.07      0.58      8.31

         20928 100.00     344.03 (avg row size 145)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
               96  128   96  128      0.67

vector row size count histogram for quant type: q6_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  2520     327  100.00     243.38      9.37      0.31

           327 100.00     243.38 (avg row size 2520)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 32064 3072 32064      9.37

vector row size count histogram for quant type: q2_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1008   41856  100.00    5373.58      7.25     77.61

         41856 100.00    5373.58 (avg row size 1008)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 8192 3072 8192      7.25

vector row size count histogram for quant type: q3_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1320   20928  66.67    1852.88      3.08     43.12
  3520   10464  33.33    2313.93      7.47     39.09

         31392 100.00    4166.81 (avg row size 2053)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             8192 3072 8192 3072      7.47


build: 9f51f2a1 (6209)

C:\llama.cpp\b612.dc_080625\build>


------------------------------


From Admin Command Prompt Window:

C:\llama.cpp\b612.dc_080625\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 2
ggml_cpu_init: from ggml-cpu-b612.c - calling ggml!ggml_init() to initialize fp16 tables
ggml_cpu_init: from ggml-cpu-b612.c - initializing GELU, SILU and EXP fp32 tables
ggml_cpu_set_tensor_repack_mode: set tensor repacking to 2



system_info: CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | OPENMP = 1 | REPACK = 1 |

| model                          |       size |     params | backend    | threads |            test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |           pp128 |        146.83 ± 3.83 |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |            tg64 |         55.28 ± 0.07 |


=== Elapsed time:    12.19s


          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20928     0.03   0.29       1.42 GGML_OP_ADD
   21255     0.03   0.26       1.25 GGML_OP_MUL
   21255     0.02   0.16       0.76 GGML_OP_RMS_NORM
   94503     9.68  94.17     102.40 GGML_OP_MUL_MAT
   10464     0.02   0.18       1.78 GGML_OP_CONT
     981     0.00   0.04       4.60 GGML_OP_GET_ROWS
   20928     0.36   3.52      17.31 GGML_OP_SET_ROWS
   10464     0.05   0.44       4.36 GGML_OP_SOFT_MAX
   20928     0.06   0.58       2.83 GGML_OP_ROPE
   10464     0.04   0.35       3.45 GGML_OP_GLU

  232170    10.28 100.00

Graph Size  #_Nodes  #_Tensors
 1126         327      368202

Total         327      368202
Total OPs Tensors      232170
Total NOP Tensors      136032 (skipped)

vector dot matrix multiply type frequency
   Count     %    Time(ms)       %   init_mat(ms) vec_dot_type
   20928   22.15     316.37     3.27     38.10    GGML_TYPE_f16
     327    0.35     285.33     2.95      0.32    GGML_TYPE_q8_K
   41856   44.29    5100.88    52.71     69.82    GGML_TYPE_q2_K_q8_K_x8
   31392   33.22    3974.98    41.07     73.33    GGML_TYPE_q3_K_q8_K_x8

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(ms) Src0 Type

   20928     0.31   3.22     0.01 ggml_type_f16
     327     0.29   2.95     0.87 ggml_type_q6_K
   41856     5.09  52.73     0.12 ggml_type_q2_K_x8
   31392     3.97  41.09     0.13 ggml_type_q3_K_x8

   94503     9.66 100.00

total number of mul_mat init conversions 94503
total elapsed init conversion time  0.18sec
average init conversion time  1.92us

total number of mul_mat repack conversions 224
total number of FAILED mul_mat repack conversions 0
total elapsed repack conversion time  1.00sec
average repack conversion time 4460.61us

vector row size count histogram for quant type: f16

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
    64    5152  24.62      35.71      0.06      3.91
   128    5120  24.46      36.06      0.07      4.59
   192   10464  50.00     164.56      0.55     21.07
   256     192   0.92      80.03      0.51      8.54

         20928 100.00     316.37 (avg row size 145)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
               96  128   96  128      0.55

vector row size count histogram for quant type: q6_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  2520     327  100.00     285.33      7.30      0.32

           327 100.00     285.33 (avg row size 2520)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 32064 3072 32064      7.30

vector row size count histogram for quant type: q2_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1008   41856  100.00    5100.88      7.02     69.82

         41856 100.00    5100.88 (avg row size 1008)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 8192 3072 8192      7.02

vector row size count histogram for quant type: q3_K_x8

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1320   20928  66.67    1717.00      2.72     38.29
  3520   10464  33.33    2257.98      6.81     35.04

         31392 100.00    3974.98 (avg row size 2053)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             8192 3072 8192 3072      6.81


build: 9f51f2a1 (6209)

C:\llama.cpp\b612.dc_080625\build>cd ..\..\dc\build

C:\llama.cpp\dc\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 2
TSC frequency in counts per second 2994267120
| model                          |       size |     params | backend    | threads |          test |              t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | ------------: | ---------------: |
Set repacking mode to 2
Started pp warmup run
Done pp warmup run
CPUInfo: AMD mNumSMT 2
xb_set_optimal_process_affinity: Detected [AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ]
Set process affinity w/ n_threads 0000000000AAAA00
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |         pp128 |    184.38 ± 7.34 |
Started tg warmup run
Done tg warmup run
CPUInfo: AMD mNumSMT 2
xb_set_optimal_process_affinity: Detected [AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ]
Set process affinity w/ n_threads 0000000000AAAA00
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |          tg64 |     55.49 ± 2.88 |


=== Elapsed time:    10.55s

 Overall Tensor Op Performance Data

Tensor ops are executed in parallel by a specified set of threads
Tensor execution time is the total time by the parallel set of threads
Total time is the seconds to execute all tensors of the specified type
Tensor time is the average ms to execute a tensor of the specified type

          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20992     0.02   0.23     1.02 GGML_OP_ADD
   31816     0.04   0.43     1.26 GGML_OP_MUL
   21320     0.01   0.10     0.46 GGML_OP_RMS_NORM
   94792     9.04  97.38    95.34 GGML_OP_MUL_MAT
   20992     0.07   0.79     3.51 GGML_OP_CPY
   10496     0.01   0.08     0.70 GGML_OP_CONT
     984     0.00   0.03     3.03 GGML_OP_GET_ROWS
   10496     0.01   0.11     0.98 GGML_OP_SOFT_MAX
   20992     0.06   0.59     2.63 GGML_OP_ROPE
   10496     0.02   0.24     2.15 GGML_OP_UNARY

  243376     9.28 100.00

Vector Dot Matrix Multiply Type Frequency

   Count     %    Time(ms)      %   vec_dot_type
   20992   22.15    200.75     2.22 GGML_TYPE_f16
     328    0.35    277.17     3.07 GGML_TYPE_q8_K
   41984   44.29   4563.43    50.50 GGML_TYPE_q2_K_q8_K_x8
   31488   33.22   3996.01    44.22 GGML_TYPE_q3_K_q8_K_x8

   94792  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(us) Src0 Type

   20992     0.20   2.45     9.48 ggml_type_f16
     328     0.28   3.42   844.82 ggml_type_q6_K
   41984     4.05  49.96    96.54 ggml_type_q2_K_x8
   31488     3.58  44.17   113.80 ggml_type_q3_K_x8

   94792     8.11 100.00

Unary Op Frequency

          Total     Total  Tensor
   Count Time(sec)   %    Time(ms) Unary Op

   10496     0.02  100.00    0.00  GGML_UNARY_OP_SILU

   10496     0.02  100.00

Tensor op dispatch spin wait information

Threads dispatch tensor ops by scanning the graph node list in parallel,
selecting an eligible tensor (i.e., one that is not NOP'ed and not empty),
executing their slice of the tensor computation, and then waiting until all
threads are finished with the tensor. At this point the scan of the node list
continues to select the next eligible tensor. Statistics are gathered for
the synchronization wait at the end of each loop iteration

total number of tensor waits 243376
total elapsed tensor wait time  0.81sec
average wait time per tensor wait  3.31us
total overall elapsed time  10.56sec
tensor wait time as percent of total elapsed time  7.63%

total number of init waits 74024
total elapsed init wait time  0.26sec
average wait time per init wait  3.58us
total overall elapsed time  10.56sec
init wait time as percent of total elapsed time  2.51%

total number of mul_mat init conversions 73800
total elapsed init conversion time  0.15sec
average init conversion time  2.00us

total number of mul_mat repack conversions 224
total number of FAILED mul_mat repack conversions 0
total elapsed repack conversion time  0.91sec
average repack conversion time 4066.84us

vector row size count histogram for quant type f16

  Size   Count    %    Time(ms)   Max(us)
    64    5216  24.85     27.43     79.00
   128    5120  24.39     31.30     16.00
   192   10496  50.00    103.44    316.00
   256     160   0.76     38.57    254.00

         20992 100.00    200.75ms

Average row size 145

  Max entry: ne00 ne01 ne10 ne11  Time(us)
               96  128   96  128    316.00

vector row size count histogram for quant type q6_K

  Size   Count    %    Time(ms)   Max(us)
  2520     328 100.00    277.17   4036.00

           328 100.00    277.17ms

Average row size 2520

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             3072 32064 3072 32064   4036.00

vector row size count histogram for quant type q2_K_x8

  Size   Count    %    Time(ms)   Max(us)
  1008   41984 100.00   4563.43   7299.00

         41984 100.00   4563.43ms

Average row size 1008

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             3072 8192 3072 8192   7299.00

vector row size count histogram for quant type q3_K_x8

  Size   Count    %    Time(ms)   Max(us)
  1320   20992  66.67   1775.89   5372.00
  3520   10496  33.33   2220.12   8815.00

         31488 100.00   3996.01ms

Average row size 2053

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             8192 3072 8192 3072   8815.00

Multiply matrix src0 block factor histogram
The block factor is the number of rows that will fit in the l1d_cache
src0-nr0 greater or equal src1-nr1 99.59%
src0-nr0 less than src1-nr1  0.41%

Computed block factor based on l1 d-cache size

Factor   Count    %    Cum %

     4    5184   5.47   5.47
     8    5120   5.40  10.87
    12   10304  10.87  21.74
    16   10496  11.07  32.81
    18     328   0.35  33.16
    32      32   0.03  33.19
    35   20992  22.15  55.34
    45   41984  44.29  99.63
    96     192   0.20  99.83
   128     160   0.17 100.00

         94792 100.00

 Graph Tensor Op Performance Data

Graph size is the number of tensors in a graph
The graph size zero bucket is the overflowed number of tensors
Graph count is the graphs with the respective graph size
Total time is the seconds to execute all graphs with the respective size
Graph time is the average ms to execute a graph with the respective size

Graph Graph   Total    Total     Graph
 Size Count  Tensors Time(sec)  Time(ms)

 1030   328   337840     10.21     31.14

Total   328   337840     10.21

Total NOP Tensors 94464
Total one task Tensors 0

 Tensor Thread Creation Performance

Creation count: 2296
Total creation Time(ms):  42.61
Thread creation time(us):  18.56



build: ff2529e (12)

C:\llama.cpp\dc\build>


------------------------------


C:\llama.cpp\so2001\bin\slmapp>llbenchza.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -repack 2
TSC frequency in counts per second 2994266400
Core parking disabled successfully.
mxcsr 0x00001f80, default rounding mode - round nearest
hypervisor present: yes

host system AVX capabilities:
  cpuid function 0x00000001
    Avx
  cpuidex function 0x00000007, subleaf 0
    Avx2
    Avx512F
    Avx512DQ
    Avx512Ifma
    Avx512BW
    Avx512VL
    Avx512Vbmi
    Avx512Vbmi2
    Avx512Vnni
    Avx512Bitalg
    Avx512Vpopcntdq
    Avx512Vp2Intersect
  cpuidex function 0x00000007, subleaf 1
    AvxVnni
    Avx512Bfloat16
  cpuidex function 0x0000000d, subleaf 0 - XSTATE features
    LegacyX87
    LegacySse
    Avx
    Avx512Opmask
    Avx512Zmmhi
    Avx512Zmm16_31

  enabled XSTATE features
    LegacyX87
    LegacySse
    Avx
    Avx512Opmask
    Avx512Zmmhi
    Avx512Zmm16_31

l1 d-cache size 48kb, type - data, SMT sharing 2
l1 i-cache size 32kb, type - instruction, SMT sharing 2
l2 cache size 1024kb, type - unified. SMT sharing 2
l3 cache size 32mb, type - unified, SMT sharing 16

total l1 cache    1.2mb
total l2 cache   16.0mb
total l3 cache   64.0mb

n_threads specified 8
logical processors per core 2
maximum logical processors 32
process group affinity set to 0x0000000000555500
processor index of master thread 8
master thread priority set to TIME_CRITICAL
| model                          |       size |     params | backend    | threads |          test |              t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | ------------: | ---------------: |
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |         pp128 |    190.72 ± 0.59 |
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |          tg64 |     54.23 ± 1.43 |

build: 6a9f5df6 (3239)
total elapsed time   11.30sec


Overall Tensor Op Performance Data

Tensor ops are executed in parallel by a specified set of threads
Tensor execution time is the total time by the parallel set of threads
Total time is the seconds to execute all tensors of the specified type
Tensor time is the average ms to execute a tensor of the specified type

          Total    Total  Tensor
   Count Time(sec)   %   Time(us) Tensor Op

   20928     0.02   0.24     1.12 GGML_OP_ADD
   31719     0.04   0.43     1.33 GGML_OP_MUL
   21255     0.01   0.11     0.51 GGML_OP_RMS_NORM
   94503     9.58  97.19   101.38 GGML_OP_MUL_MAT
   20928     0.06   0.65     3.08 GGML_OP_CPY
   10464     0.01   0.08     0.73 GGML_OP_CONT
     981     0.00   0.03     3.19 GGML_OP_GET_ROWS
   10464     0.01   0.11     1.08 GGML_OP_SOFT_MAX
   20928     0.09   0.89     4.20 GGML_OP_ROPE
   10464     0.03   0.26     2.49 GGML_OP_UNARY

  242634     9.86 100.00

Vector Dot Matrix Multiply Type Frequency

   Count     %

   20928   22.15 GGML_TYPE_f16
     327    0.35 GGML_TYPE_q8_K
   41856   44.29 GGML_TYPE_q2_K_q8_K_x8
   31392   33.22 GGML_TYPE_q3_K_q8_K_x8

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(us) Src0 Type

   20928     0.21   2.50    10.20 ggml_type_f16
     327     0.29   3.35   874.54 ggml_type_q6_K
   41856     4.29  50.20   102.38 ggml_type_q2_K_x8
   31392     3.75  43.95   119.53 ggml_type_q3_K_x8

   94503     8.54 100.00

Unary Op Frequency

          Total    Total   Tensor
   Count Time(sec)   %    Time(ms) Unary Op

   10464     0.03  100.00    0.00  GGML_UNARY_OP_SILU

   10464     0.03  100.00

Tensor op dispatch spin wait information

Threads dispatch tensor ops by scanning the graph node list in parallel,
selecting an eligible tensor (i.e., one that is not NOP'ed and not empty),
executing their slice of the tensor computation, and then waiting until all
threads are finished with the tensor. At this point the scan of the node list
continues to select the next eligible tensor. Statistics are gathered for
the synchronization wait at the end of each loop iteration

total number of tensor waits 242634
total elapsed tensor wait time  0.81sec
average wait time per tensor wait  3.33us
total overall elapsed time  11.30sec
tensor wait time as percent of total elapsed time  7.16%

total number of init waits 73799
total elapsed init wait time  0.29sec
average wait time per init wait  3.92us
total overall elapsed time  11.30sec
init wait time as percent of total elapsed time  2.56%

total number of mul_mat init conversions 73575
total elapsed init conversion time  0.17sec
average init conversion time  2.27us

total number of mul_mat repack conversions 224
total elapsed repack conversion time  1.03sec
average repack conversion time 4591.15us

vector row size count histogram for quant type f16

  Size   Count    %

    64    5152  24.62
   128    5120  24.46
   192   10464  50.00
   256     192   0.92

         20928 100.00

Average row size 145

vector row size count histogram for quant type q6_K

  Size   Count    %

  2520     327  100.00

           327 100.00

Average row size 2520

vector row size count histogram for quant type q2_K_x8

  Size   Count    %

  1008   41856  100.00

         41856 100.00

Average row size 1008

vector row size count histogram for quant type q3_K_x8

  Size   Count    %

  1320   20928  66.67
  3520   10464  33.33

         31392 100.00

Average row size 2053

Multiply matrix src0 block factor histogram
The block factor is the number of rows that will fit in the l1d_cache
src0-nr0 greater or equal src1-nr1 99.59%
src0-nr0 less than src1-nr1  0.41%

Computed block factor based on l1 d-cache size

Factor   Count    %    Cum %

     4    5152   5.45   5.45
     8    5120   5.42  10.87
    12   10272  10.87  21.74
    16   10464  11.07  32.81
    18     327   0.35  33.16
    35   20928  22.15  55.30
    45   41856  44.29  99.59
    96     192   0.20  99.80
   128     192   0.20 100.00

         94503 100.00

 Graph Tensor Op Performance Data

Graph size is the number of tensors in a graph
The graph size zero bucket is the overflowed number of tensors
Graph count is the graphs with the respective graph size
Total time is the seconds to execute all graphs with the respective size
Graph time is the average ms to execute a graph with the respective size

Graph Graph   Total    Total     Graph
 Size Count  Tensors  Time(sec) Time(ms)

 1030   327   336810     10.79     32.98

Total   327   336810     10.79

Total NOP Tensors 94176
Total one task Tensors 0

 Tensor Thread Creation Performance

Creation count: 2289
Total creation Time(ms):  41.71
Thread creation time(us):  18.22



C:\llama.cpp\so2001\bin\slmapp>


--------------------------


C:\llama.cpp\dc\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin -repack 2
TSC frequency in counts per second 2994267120
| model                          |       size |     params | backend    | threads |          test |              t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | ------------: | ---------------: |
Set repacking mode to 2
Started pp warmup run
Done pp warmup run
CPUInfo: AMD mNumSMT 2
xb_set_optimal_process_affinity: Detected [AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ]
Set process affinity w/ n_threads 0000000000AAAA00
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |         pp128 |    184.38 ± 7.34 |
Started tg warmup run
Done tg warmup run
CPUInfo: AMD mNumSMT 2
xb_set_optimal_process_affinity: Detected [AMD RYZEN AI MAX+ 395 w/ Radeon 8060S          ]
Set process affinity w/ n_threads 0000000000AAAA00
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |          tg64 |     55.49 ± 2.88 |


=== Elapsed time:    10.55s

 Overall Tensor Op Performance Data

Tensor ops are executed in parallel by a specified set of threads
Tensor execution time is the total time by the parallel set of threads
Total time is the seconds to execute all tensors of the specified type
Tensor time is the average ms to execute a tensor of the specified type

          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20992     0.02   0.23     1.02 GGML_OP_ADD
   31816     0.04   0.43     1.26 GGML_OP_MUL
   21320     0.01   0.10     0.46 GGML_OP_RMS_NORM
   94792     9.04  97.38    95.34 GGML_OP_MUL_MAT
   20992     0.07   0.79     3.51 GGML_OP_CPY
   10496     0.01   0.08     0.70 GGML_OP_CONT
     984     0.00   0.03     3.03 GGML_OP_GET_ROWS
   10496     0.01   0.11     0.98 GGML_OP_SOFT_MAX
   20992     0.06   0.59     2.63 GGML_OP_ROPE
   10496     0.02   0.24     2.15 GGML_OP_UNARY

  243376     9.28 100.00

Vector Dot Matrix Multiply Type Frequency

   Count     %    Time(ms)      %   vec_dot_type
   20992   22.15    200.75     2.22 GGML_TYPE_f16
     328    0.35    277.17     3.07 GGML_TYPE_q8_K
   41984   44.29   4563.43    50.50 GGML_TYPE_q2_K_q8_K_x8
   31488   33.22   3996.01    44.22 GGML_TYPE_q3_K_q8_K_x8

   94792  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(us) Src0 Type

   20992     0.20   2.45     9.48 ggml_type_f16
     328     0.28   3.42   844.82 ggml_type_q6_K
   41984     4.05  49.96    96.54 ggml_type_q2_K_x8
   31488     3.58  44.17   113.80 ggml_type_q3_K_x8

   94792     8.11 100.00

Unary Op Frequency

          Total     Total  Tensor
   Count Time(sec)   %    Time(ms) Unary Op

   10496     0.02  100.00    0.00  GGML_UNARY_OP_SILU

   10496     0.02  100.00

Tensor op dispatch spin wait information

Threads dispatch tensor ops by scanning the graph node list in parallel,
selecting an eligible tensor (i.e., one that is not NOP'ed and not empty),
executing their slice of the tensor computation, and then waiting until all
threads are finished with the tensor. At this point the scan of the node list
continues to select the next eligible tensor. Statistics are gathered for
the synchronization wait at the end of each loop iteration

total number of tensor waits 243376
total elapsed tensor wait time  0.81sec
average wait time per tensor wait  3.31us
total overall elapsed time  10.56sec
tensor wait time as percent of total elapsed time  7.63%

total number of init waits 74024
total elapsed init wait time  0.26sec
average wait time per init wait  3.58us
total overall elapsed time  10.56sec
init wait time as percent of total elapsed time  2.51%

total number of mul_mat init conversions 73800
total elapsed init conversion time  0.15sec
average init conversion time  2.00us

total number of mul_mat repack conversions 224
total number of FAILED mul_mat repack conversions 0
total elapsed repack conversion time  0.91sec
average repack conversion time 4066.84us

vector row size count histogram for quant type f16

  Size   Count    %    Time(ms)   Max(us)
    64    5216  24.85     27.43     79.00
   128    5120  24.39     31.30     16.00
   192   10496  50.00    103.44    316.00
   256     160   0.76     38.57    254.00

         20992 100.00    200.75ms

Average row size 145

  Max entry: ne00 ne01 ne10 ne11  Time(us)
               96  128   96  128    316.00

vector row size count histogram for quant type q6_K

  Size   Count    %    Time(ms)   Max(us)
  2520     328 100.00    277.17   4036.00

           328 100.00    277.17ms

Average row size 2520

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             3072 32064 3072 32064   4036.00

vector row size count histogram for quant type q2_K_x8

  Size   Count    %    Time(ms)   Max(us)
  1008   41984 100.00   4563.43   7299.00

         41984 100.00   4563.43ms

Average row size 1008

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             3072 8192 3072 8192   7299.00

vector row size count histogram for quant type q3_K_x8

  Size   Count    %    Time(ms)   Max(us)
  1320   20992  66.67   1775.89   5372.00
  3520   10496  33.33   2220.12   8815.00

         31488 100.00   3996.01ms

Average row size 2053

  Max entry: ne00 ne01 ne10 ne11  Time(us)
             8192 3072 8192 3072   8815.00

Multiply matrix src0 block factor histogram
The block factor is the number of rows that will fit in the l1d_cache
src0-nr0 greater or equal src1-nr1 99.59%
src0-nr0 less than src1-nr1  0.41%

Computed block factor based on l1 d-cache size

Factor   Count    %    Cum %

     4    5184   5.47   5.47
     8    5120   5.40  10.87
    12   10304  10.87  21.74
    16   10496  11.07  32.81
    18     328   0.35  33.16
    32      32   0.03  33.19
    35   20992  22.15  55.34
    45   41984  44.29  99.63
    96     192   0.20  99.83
   128     160   0.17 100.00

         94792 100.00

 Graph Tensor Op Performance Data

Graph size is the number of tensors in a graph
The graph size zero bucket is the overflowed number of tensors
Graph count is the graphs with the respective graph size
Total time is the seconds to execute all graphs with the respective size
Graph time is the average ms to execute a graph with the respective size

Graph Graph   Total    Total     Graph
 Size Count  Tensors Time(sec)  Time(ms)

 1030   328   337840     10.21     31.14

Total   328   337840     10.21

Total NOP Tensors 94464
Total one task Tensors 0

 Tensor Thread Creation Performance

Creation count: 2296
Total creation Time(ms):  42.61
Thread creation time(us):  18.56



build: ff2529e (12)

C:\llama.cpp\dc\build>


-------------------------------


C:\llama.cpp\b612.dc\build>bin\RelWithDebInfo\llama-bench.exe -t 8 -p 128 -n 64 -m c:\llama.cpp\models\Phi-3\Phi-3-mini-4k-instruct-Q2_K-MS.gguf -paffin
ggml_cpu_init: from ggml-cpu-b612.c - calling ggml!ggml_init() to initialize fp16 tables
ggml_cpu_init: from ggml-cpu-b612.c - initializing GELU, SILU and EXP fp32 tables



system_info: CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | OPENMP = 1 | AARCH64_REPACK = 1 |

| model                          |       size |     params | backend    | threads |          test |                  t/s |
| ------------------------------ | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |         pp128 |       105.49 ± 13.67 |
Set process affinity w/ n_threads 0000000000555500
| llama 7B Q2_K - Medium         |   1.35 GiB |     3.82 B | CPU        |       8 |          tg64 |         50.80 ± 0.10 |


=== Elapsed time:    13.93s


 OpenMP runs = 0

          Total     Total  Tensor
   Count Time(sec)   %     Time(us) Tensor Op
   20928     0.04   0.30       1.84 GGML_OP_ADD
   31719     0.05   0.39       1.57 GGML_OP_MUL
   21255     0.02   0.16       0.96 GGML_OP_RMS_NORM
   94503    12.45  97.33     131.77 GGML_OP_MUL_MAT
   20928     0.08   0.62       3.76 GGML_OP_CPY
   10464     0.02   0.12       1.49 GGML_OP_CONT
     981     0.01   0.04       5.75 GGML_OP_GET_ROWS
   10464     0.02   0.13       1.62 GGML_OP_SOFT_MAX
   20928     0.07   0.58       3.56 GGML_OP_ROPE
   10464     0.04   0.32       3.92 GGML_OP_UNARY

  242634    12.79 100.00

Graph Size  #_Nodes  #_Tensors
 1094         327      357738

Total         327      357738
Total OPs Tensors      242634
Total NOP Tensors      115104 (skipped)

vector dot matrix multiply type frequency
   Count     %    Time(ms)       %   init_mat(ms) vec_dot_type
   20928   22.15     611.89     4.91    472.31    GGML_TYPE_f16
   73575   77.85   11840.46    95.09    389.34    GGML_TYPE_q8_K

   94503  100.00

Vector Dot Matrix Multiply Src0 Type Frequency

          Total    Total  Tensor
   Count Time(sec)   %   Time(ms) Src0 Type

   20928     0.61   4.89     0.03 ggml_type_f16
   41856     6.04  48.58     0.14 ggml_type_q2_K
   31392     5.52  44.36     0.18 ggml_type_q3_K
     327     0.27   2.17     0.82 ggml_type_q6_K

   94503    12.43 100.00

vector row size count histogram for quant type: f16

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
    64    5152  24.62      71.97      0.10     61.28
   128    5120  24.46      50.15      0.03     51.03
   192   10464  50.00     324.99      1.31    448.53
   256     192   0.92     164.78      0.97    291.68

         20928 100.00     611.89 (avg row size 145)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
               96  128   96  128      1.31

vector row size count histogram for quant type: q2_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1008   41856  100.00    6049.42      9.66    217.93

         41856 100.00    6049.42 (avg row size 1008)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 8192 3072 8192      9.66

vector row size count histogram for quant type: q3_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  1320   20928  66.67    2502.79      4.71     94.95
  3520   10464  33.33    3018.81     11.98    152.85

         31392 100.00    5521.60 (avg row size 2053)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             8192 3072 8192 3072     11.98

vector row size count histogram for quant type: q6_K

  Size   Count    %     Time(ms)    Max(ms) From_Float(ms)
  2520     327  100.00     269.44     14.80      0.62

           327 100.00     269.44 (avg row size 2520)

  Max entry: ne00 ne01 ne10 ne11  Time(ms)
             3072 32064 3072 32064     14.80


build: 7ddf38e4 (5239)

C:\llama.cpp\b612.dc\build>

